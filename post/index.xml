<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Heba Moh.</title>
    <link>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/</link>
    <description>Recent content in Projects on Heba Moh.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 Jan 2020 12:00:00 -0500</lastBuildDate><atom:link href="https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Airport Agenda using Dijkstra&#39;s algorithm</title>
      <link>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/airport-agenda-using-dijkstras-algorithm/</link>
      <pubDate>Sat, 18 Dec 2021 11:00:59 -0400</pubDate>
      
      <guid>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/airport-agenda-using-dijkstras-algorithm/</guid>
      <description>Abstract Reserving air flights can be a complex problem, especially between cities not connected by a direct flight. The goal of this project is to apply Dijkstra’s Algorithm to find the shortest path from starting airport to destination airport, such that minimizes the total travel distance to its destination.
Tools  Python json library. Python math library. Python system library. Python pandas library. Spyder IDE.  Dataset We are given a json file contains a list of airports with some geo-information like city, country and location (longitude, latitude) , airport id as well as airport specific designations (a list of destination airports) as shown below:</description>
    </item>
    
    <item>
      <title>Hotel Bookings Cancellation Classification</title>
      <link>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/hotel-bookings-cancellation-classification/</link>
      <pubDate>Thu, 16 Dec 2021 10:58:08 -0400</pubDate>
      
      <guid>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/hotel-bookings-cancellation-classification/</guid>
      <description>Abstract In tourism and travel-related industries, most of the research on Revenue Management demand forecasting and prediction problems employ data from the aviation industry, in the format known as the Passenger Name Record (PNR). This is a format developed by the aviation industry. The main goal is to generate meaningful estimators from the data set we have and then choose the model that best predicts cancellation by comparing it to the accuracy ratings of several ML models.</description>
    </item>
    
    <item>
      <title>Bangalore House Price Prediction</title>
      <link>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/bangalore-house-price-prediction/</link>
      <pubDate>Sun, 05 Dec 2021 11:25:05 -0400</pubDate>
      
      <guid>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/bangalore-house-price-prediction/</guid>
      <description>Abstract Buying a home, especially in a city like Bengaluru, is a tricky choice. While the major factors are usually the same for all metros, there are others to be considered for the Silicon Valley of India. With its help millennial crowd, vibrant culture, great climate, and a slew of job opportunities, it is difficult to ascertain the price of a house in Bengaluru.
By cleaning and analyzing the Bangalore home dataset, we will be able to understand how house prices are affected by various factors, and then apply machine learning regression to establish an approximate price for the properties.</description>
    </item>
    
    <item>
      <title>Computer Repair shop Database</title>
      <link>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/computer-repair-shop-database/</link>
      <pubDate>Sun, 05 Dec 2021 11:25:05 -0400</pubDate>
      
      <guid>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/computer-repair-shop-database/</guid>
      <description>Problem Specification The owners of a computer repair shop would like to keep track of the repair jobs for computers they repair, the items used for each repair job, the labor costs for each repair job, the repairmen performing each repair job, and the total cost of each repair job. When customers bring their computers in to be repaired, they make a deposit on the repair job and are given a date to return and uplift their computer.</description>
    </item>
    
    <item>
      <title>Median Housing Price Prediction</title>
      <link>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/median-housing-price-prediction/</link>
      <pubDate>Fri, 26 Nov 2021 11:15:58 -0400</pubDate>
      
      <guid>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/median-housing-price-prediction/</guid>
      <description>Problem Statements In a Machine Learning Housing Corporation! The first task you are asked to perform is to build a model of housing prices in California using the California census data.
The model should learn from this data and be able to predict the median housing price in any district, given all the other metrics.
Dataset The California Housing Prices dataset from the StatLib repository. This dataset was based on data from the 1990 California census.</description>
    </item>
    
    <item>
      <title>Melanoma Classification</title>
      <link>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/melanoma-classification/</link>
      <pubDate>Mon, 15 Nov 2021 11:25:05 -0400</pubDate>
      
      <guid>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/melanoma-classification/</guid>
      <description>Abstract Skin cancer is the out-of-control growth of irregular skin cells causing the skin to rapidly multiply and form malignant tumors. Between 2008 and 2019 the number of new invasive Melanoma cases rapidly increased by 54%. With such a substantial escalation, it is of great importance for us to inaugurate and build on techniques to assist healthcare providers in diagnosing skin cancer at its preliminary stages.
I developed a classification model for classifying the images to Melanoma or not motivated by the performance of Convolutional Neural Networks in computer vision, I present a CNN-based model from scratch.</description>
    </item>
    
    <item>
      <title>Smart Rehabilitation</title>
      <link>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/smart-rehabilitation/</link>
      <pubDate>Fri, 12 Nov 2021 11:14:48 -0400</pubDate>
      
      <guid>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/smart-rehabilitation/</guid>
      <description>Ploblem Specification You are a CEO of an AI company which builds and sells AI software to different types of clients. A client of yours is Maha, a Physiotherapist who helps people build customized rehabilitation plans that fits their health conditions and abilities. Maha told you that it takes her a long time to build rehabilitation exercise plans for her customers since it varies according to the customer Age Category, Condition and No.</description>
    </item>
    
    <item>
      <title>Web Scraping Job Postings from Indeed</title>
      <link>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/web-scraping-job-postings-from-indeed/</link>
      <pubDate>Fri, 05 Nov 2021 11:25:05 -0400</pubDate>
      
      <guid>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/web-scraping-job-postings-from-indeed/</guid>
      <description>Problem Specifications Indeed is a website that helps connect employers and job seekers through job postings, company reviews, salary data, and more. Because the Indeed site is full of relevant data, organizations can extract job data from the Indeed API for analysis. Web scraping, which is the automatic extraction of data from a webpage, is the best tool for extracting data from Indeed quickly, cheaply, and securely. Through scraping Indeed, an organization can establish a competitive salary, gain understanding of employee sentiment and values, find great candidates, and build a realistic budget for hiring employees and outside contractors.</description>
    </item>
    
    <item>
      <title>University Accommodation Office Database</title>
      <link>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/university-accommodation-office-database/</link>
      <pubDate>Wed, 15 Sep 2021 11:25:05 -0400</pubDate>
      
      <guid>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/university-accommodation-office-database/</guid>
      <description>Problem Specification The director of the University Accommodation Office requires you to design a database to assist with the administration of the office. The requirements collection and analysis phase of the database design process has provided the following data requirements specification for the University Accommodation Office database followed by examples of query transactions that should be supported by the database.
Tools   MySQL shell MySQL workbench Sublime text editor Draw.</description>
    </item>
    
    <item>
      <title>WERateDogs Data Wrangling</title>
      <link>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/weratedogs-data-wrangling/</link>
      <pubDate>Tue, 15 Dec 2020 11:25:05 -0400</pubDate>
      
      <guid>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/weratedogs-data-wrangling/</guid>
      <description>Problem Specification The purpose of this project is to put in practice what I learned in data wrangling data section from Udacity Data Analysis Nanodegree program. The dataset that you will be wrangling (and analyzing and visualizing) is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people&amp;rsquo;s dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/temp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/temp/</guid>
      <description>Abstract Tools   Time Library Pandas Library NumPy Library Matplotlib Library Sklearn Library Keras APIs. Local Jupter Notebook. Word and power point.  Prject Stages  Conclusion  More Resources   For more details see the project repository on github.
  Dispaly the project detailed report from here
  Dispaly the project presentation from here
  Easy displaying the project notebook from here
  </description>
    </item>
    
    <item>
      <title>Bike Sharing Systems</title>
      <link>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/bike-sharing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/bike-sharing/</guid>
      <description>Problem Specification  Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.</description>
    </item>
    
    <item>
      <title>BikeSharing Exploration</title>
      <link>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/bikesharing-exploration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://heba14101998.github.io/Heba-Mohamed-portofolio-github.io/post/bikesharing-exploration/</guid>
      <description>Problem Specification  In this project, I used Python to explore data related to bike share systems for three major cities in the United States—Chicago, New York City, and Washington. I wrote code to import the data and answer interesting questions about it by computing descriptive statistics. I also wrote a script that takes in raw input to create an interactive experience in the terminal to present these statistics.
Tools   Python 3.</description>
    </item>
    
  </channel>
</rss>
